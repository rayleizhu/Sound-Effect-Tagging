{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from scipy import stats\n",
    "random.seed(100)\n",
    "import csv\n",
    "from scipy import io\n",
    "import pickle\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# https://stackoverflow.com/questions/5364050/reloading-submodules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAudio(info):\n",
    "    display(Audio(info['previews']['preview-lq-mp3']))\n",
    "\n",
    "def load_pickle(fname):\n",
    "    f = open(fname, 'rb')\n",
    "    out = pickle.load(f)\n",
    "    f.close()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags  = load_pickle('train_tags.pickle3')\n",
    "train_mfccs = load_pickle('train_mfccs.pickle3')\n",
    "train_info  = load_pickle('train_info.pickle3')\n",
    "\n",
    "test_mfccs = load_pickle('test_mfccs.pickle3')\n",
    "test_info  = load_pickle('test_info.pickle3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute delta MFCCs\n",
    "def compute_delta_mfccs(mfccs):\n",
    "    dmfccs = []\n",
    "    for m in mfccs:\n",
    "        tmp = m[1:] - m[0:-1]\n",
    "        dm = hstack((m[0:-1], tmp))\n",
    "        dmfccs.append(dm)\n",
    "    return dmfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dmfccs = compute_delta_mfccs(train_mfccs)\n",
    "test_dmfccs  = compute_delta_mfccs(test_mfccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acoust: 100\n",
      "analog: 100\n",
      "bass: 160\n",
      "beat: 128\n",
      "drum: 371\n",
      "effect: 141\n",
      "electron: 194\n",
      "field: 110\n",
      "glitch: 110\n",
      "guitar: 130\n",
      "hit: 110\n",
      "loop: 237\n",
      "machin: 100\n",
      "metal: 117\n",
      "nois: 199\n",
      "percuss: 285\n",
      "record: 192\n",
      "space: 125\n",
      "synth: 220\n",
      "synthes: 136\n",
      "vocal: 120\n",
      "voic: 167\n"
     ]
    }
   ],
   "source": [
    "tagnames, tagnames_counts = unique(concatenate(train_tags), return_counts=True)\n",
    "for a,b in zip(tagnames, tagnames_counts):\n",
    "    print(\"{}: {}\".format(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list of tags into binary class labels\n",
    "def tags2class(tags, tagnames):\n",
    "    b = zeros(shape=(len(tags), len(tagnames)))\n",
    "    for i,t in enumerate(tags):\n",
    "        for j,n in enumerate(tagnames):\n",
    "            if n in t:\n",
    "                b[i,j] = 1\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_classes[i,j] = absence/presence of the j-th tag in the i-th sound\n",
    "train_classes = tags2class(train_tags, tagnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100., 100., 160., 128., 371., 141., 194., 110., 110., 130., 110.,\n",
       "       237., 100., 117., 199., 285., 192., 125., 220., 136., 120., 167.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check we did this correctly...\n",
    "# it should be the same as the tag counts above\n",
    "sum(train_classes,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_csv_kaggle_tags(fname, tagnames, Yscores):\n",
    "    # header\n",
    "    tmp = [['Id']]\n",
    "    for t in tagnames:\n",
    "        tmp[0].append(t)    \n",
    "    \n",
    "    # add ID numbers for each Y, and usage if necessary\n",
    "    for i in range(len(Yscores)):\n",
    "        tmp2 = [(i+1)]\n",
    "        for t in range(len(tagnames)):\n",
    "            tmp2.append(Yscores[i,t])\n",
    "        \n",
    "        tmp.append(tmp2)\n",
    "        \n",
    "    # write CSV file\n",
    "    f = open(fname, 'w')\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(tmp)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## NN experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes: 22\n",
      "number of training samples: 1788\n",
      "number of testing samples: 262\n",
      "number of positives in each class:\n",
      " [100. 100. 160. 128. 371. 141. 194. 110. 110. 130. 110. 237. 100. 117.\n",
      " 199. 285. 192. 125. 220. 136. 120. 167.]\n",
      "train_mfccs[0].shape: (345, 13)\n",
      "train_classes.shape: (1788, 22)\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(tagnames)\n",
    "num_train = len(train_mfccs)\n",
    "num_test = len(test_mfccs)\n",
    "pos_cnt = train_classes.sum(0)\n",
    "\n",
    "print(f'num_classes: {num_classes}')\n",
    "print(f'number of training samples: {num_train}')\n",
    "print(f'number of testing samples: {num_test}')\n",
    "print(f'number of positives in each class:\\n {pos_cnt}')\n",
    "\n",
    "\n",
    "print(f'train_mfccs[0].shape: {train_mfccs[0].shape}')\n",
    "print(f'train_classes.shape: {train_classes.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an ROC curve using class labels and class scores\n",
    "class AUROC(object):\n",
    "    def __init__(self, unique_tag_num=22):\n",
    "        self.unique_tag_num = unique_tag_num\n",
    "    \n",
    "    def __call__(self, Yscores, Yclasses):\n",
    "        fprall = []\n",
    "        tprall = []\n",
    "        aucall = []\n",
    "        for i in range(self.unique_tag_num):\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(Yclasses[:,i], Yscores[:,i])\n",
    "#             plt.plot(fpr, tpr, lw=0.5, alpha=0.5)\n",
    "            auc = metrics.auc(fpr, tpr)\n",
    "            fprall.append(fpr)\n",
    "            tprall.append(tpr)\n",
    "            aucall.append(auc)\n",
    "\n",
    "        # Then interpolate all ROC curves at this points\n",
    "        all_fpr = unique(concatenate(fprall))\n",
    "        mean_tpr = zeros_like(all_fpr)\n",
    "        for i in range(self.unique_tag_num):\n",
    "            mean_tpr += interp(all_fpr, fprall[i], tprall[i])\n",
    "\n",
    "        # Finally average it and compute AUC\n",
    "        mean_tpr /= self.unique_tag_num\n",
    "\n",
    "        # auc of the average ROC curve\n",
    "        auc = metrics.auc(all_fpr, mean_tpr)\n",
    "\n",
    "        # average AUC\n",
    "        mc_auc = mean(aucall)\n",
    "    \n",
    "        return mc_auc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from extra.dataset import MFCCDataset, MyPadCollate\n",
    "import logging\n",
    "\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "SEED = 10086\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "# https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936/3\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test MFCCDataset and MyPadCollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_dataset = MFCCDataset(train_mfccs, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc_diff:  0.0\n",
      "label_diff:  0.0\n",
      "mfcc_diff:  0.0\n",
      "label_diff:  0.0\n",
      "mfcc_diff:  0.0\n",
      "label_diff:  0.0\n",
      "mfcc_diff:  0.0\n",
      "label_diff:  0.0\n",
      "mfcc_diff:  0.0\n",
      "label_diff:  0.0\n",
      "mfcc_diff:  0.0\n",
      "label_diff:  0.0\n",
      "mfcc_diff:  0.0\n",
      "label_diff:  0.0\n",
      "mfcc_diff:  0.0\n",
      "label_diff:  0.0\n",
      "mfcc_diff:  0.0\n",
      "label_diff:  0.0\n",
      "mfcc_diff:  0.0\n",
      "label_diff:  0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    mfcc, label = mfcc_dataset[i]\n",
    "    mfcc_diff = mfcc.numpy() - train_mfccs[i]\n",
    "    print('mfcc_diff: ', np.sum(np.abs(mfcc_diff)))\n",
    "    label_diff = label.numpy() - train_classes[i]\n",
    "    print('label_diff: ', np.sum(np.abs(label_diff)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "allloader = DataLoader(mfcc_dataset,\n",
    "                             batch_size=64,\n",
    "                             collate_fn=MyPadCollate(batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1111, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1123, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1161, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1274, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 638, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1926, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 432, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1256, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 865, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 814, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1212, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 546, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1293, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1109, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 714, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1222, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1193, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1197, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1183, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1260, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1227, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 958, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1191, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1119, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1041, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 1026, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([64, 600, 13])\n",
      "torch.Size([64, 22])\n",
      "torch.Size([60, 800, 13])\n",
      "torch.Size([60, 22])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(data_loader):\n",
    "    x, y = batch\n",
    "    print(x.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split dataset to train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1609\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "train_val_split_ratio = 0.9\n",
    "train_num = int(train_val_split_ratio * len(mfcc_dataset))\n",
    "valid_num = len(mfcc_dataset) - train_num\n",
    "mfcc_train, mfcc_valid = random_split(mfcc_dataset,\n",
    "                                      (train_num, valid_num))\n",
    "\n",
    "print(len(mfcc_train))\n",
    "print(len(mfcc_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for dt, gt in dataloader:\n",
    "        dt = dt.float().cuda()\n",
    "        gt = gt.float().cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(dt)\n",
    "        loss = criterion(predictions, gt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        \n",
    "    return epoch_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    \n",
    "    preds = []\n",
    "    gts = []\n",
    "    with torch.no_grad():\n",
    "        for dt, gt in dataloader:\n",
    "            dt = dt.float().cuda()\n",
    "            gt = gt.float().cuda()\n",
    "            predictions = model(dt)\n",
    "            preds.append(predictions)\n",
    "            gts.append(gt)\n",
    "            \n",
    "    preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    gts = torch.cat(gts, dim=0).cpu().numpy()\n",
    "    score = criterion(preds, gts)\n",
    "\n",
    "    return preds, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extra.nn_model import GRUTagging\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "def grid_search(model_name, param_grid, trainloader, validloader, n_epochs=50):\n",
    "    param_combs = list(ParameterGrid(param_grid))\n",
    "    global_best_score = 0.\n",
    "    best_save_path = None\n",
    "    for comb in param_combs:\n",
    "        model_kwargs = {}\n",
    "        loss_kwargs = {}\n",
    "        optim_kwargs = {}\n",
    "        for key, val in comb.items():\n",
    "            component, arg = key.split('.')\n",
    "            if component == 'loss':\n",
    "                loss_kwargs[arg] = val\n",
    "            elif component == 'model':\n",
    "                model_kwargs[arg] = val\n",
    "            elif component == 'optim':\n",
    "                optim_kwargs[arg] = val\n",
    "            else:\n",
    "                raise ValueError(f'Unknow component {component}.')\n",
    "        \n",
    "        if model_name == 'gru':\n",
    "            model = GRUTagging(batch_first=True, **model_kwargs).cuda()\n",
    "        else:\n",
    "            raise NotImplementedError(f'Model {model_name} is not implemented.')\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), **optim_kwargs)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "                                              step_size=n_epochs//3,\n",
    "                                              gamma=0.5)\n",
    "        criterion = nn.BCEWithLogitsLoss(**loss_kwargs).cuda()\n",
    "        val_criterion = AUROC(len(tagnames))\n",
    "        \n",
    "        epoch_best_valid_score = 0.\n",
    "        \n",
    "        logging.info(f'training model {model_name}.'\\\n",
    "                     f'\\n\\t -model_kwargs: {model_kwargs}'\\\n",
    "                     f'\\n\\t -loss_kwargs: {loss_kwargs}'\\\n",
    "                     f'\\n\\t -optim_kwargs: {optim_kwargs}')\n",
    "        \n",
    "        for epoch in range(1, n_epochs+1):\n",
    "            scheduler.step()\n",
    "            \n",
    "            train_loss = train(model, trainloader, optimizer, criterion)\n",
    "            preds, (mc_auc, auc) = evaluate(model, validloader, val_criterion)\n",
    "            \n",
    "            if mc_auc > epoch_best_valid_score:\n",
    "                epoch_best_valid_score = mc_auc\n",
    "                save_dict = {'model_name': model_name,\n",
    "                             'model_kwargs': model_kwargs,\n",
    "                             'loss_kwargs': loss_kwargs,\n",
    "                             'optim_kwargs': optim_kwargs,\n",
    "                             'model_state_dict': model.state_dict()}\n",
    "                save_path = f'ckpt/{model_name}_mcauc_{mc_auc:.3f}.pt'\n",
    "                torch.save(save_dict, save_path)\n",
    "                if mc_auc > global_best_score:\n",
    "                    global_best_score = mc_auc\n",
    "                    best_save_path = save_path\n",
    "                \n",
    "            logging.info(f'Epoch: {epoch:02}/{n_epochs} | '\\\n",
    "                         f'Train Loss: {train_loss:.3f} | Valid. MCAUC: {mc_auc:.3f}')\n",
    "    return best_save_path, global_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path):\n",
    "    save_dict = torch.load(ckpt_path)\n",
    "    if save_dict['model_name'] == 'gru':\n",
    "        model = GRUTagging(batch_first=True, **save_dict['model_kwargs']).cuda()\n",
    "    else:\n",
    "        raise NotImplementedError(f'Model {model_name} is not implemented.')\n",
    "    model.load_state_dict(save_dict['model_state_dict'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-30 15:50:21,350 - INFO - training model gru.\n",
      "\t -model_kwargs: {'dropout': 0.3, 'hidden_dim': 256, 'n_layers': 2}\n",
      "\t -loss_kwargs: {'pos_weight': None}\n",
      "\t -optim_kwargs: {'lr': 0.001}\n",
      "2020-03-30 15:50:27,371 - INFO - Epoch: 01/50 | Train Loss: 0.337 | Valid. MCAUC: 0.605\n",
      "2020-03-30 15:50:33,352 - INFO - Epoch: 02/50 | Train Loss: 0.295 | Valid. MCAUC: 0.651\n",
      "2020-03-30 15:50:39,312 - INFO - Epoch: 03/50 | Train Loss: 0.287 | Valid. MCAUC: 0.701\n",
      "2020-03-30 15:50:45,341 - INFO - Epoch: 04/50 | Train Loss: 0.279 | Valid. MCAUC: 0.728\n",
      "2020-03-30 15:50:51,330 - INFO - Epoch: 05/50 | Train Loss: 0.272 | Valid. MCAUC: 0.743\n",
      "2020-03-30 15:50:57,292 - INFO - Epoch: 06/50 | Train Loss: 0.266 | Valid. MCAUC: 0.754\n",
      "2020-03-30 15:51:03,315 - INFO - Epoch: 07/50 | Train Loss: 0.259 | Valid. MCAUC: 0.771\n",
      "2020-03-30 15:51:09,287 - INFO - Epoch: 08/50 | Train Loss: 0.251 | Valid. MCAUC: 0.770\n",
      "2020-03-30 15:51:15,243 - INFO - Epoch: 09/50 | Train Loss: 0.245 | Valid. MCAUC: 0.780\n",
      "2020-03-30 15:51:21,219 - INFO - Epoch: 10/50 | Train Loss: 0.238 | Valid. MCAUC: 0.782\n",
      "2020-03-30 15:51:27,211 - INFO - Epoch: 11/50 | Train Loss: 0.232 | Valid. MCAUC: 0.795\n",
      "2020-03-30 15:51:33,207 - INFO - Epoch: 12/50 | Train Loss: 0.229 | Valid. MCAUC: 0.795\n",
      "2020-03-30 15:51:39,165 - INFO - Epoch: 13/50 | Train Loss: 0.223 | Valid. MCAUC: 0.803\n",
      "2020-03-30 15:51:45,186 - INFO - Epoch: 14/50 | Train Loss: 0.218 | Valid. MCAUC: 0.812\n",
      "2020-03-30 15:51:51,171 - INFO - Epoch: 15/50 | Train Loss: 0.213 | Valid. MCAUC: 0.811\n",
      "2020-03-30 15:51:57,132 - INFO - Epoch: 16/50 | Train Loss: 0.207 | Valid. MCAUC: 0.812\n",
      "2020-03-30 15:52:03,129 - INFO - Epoch: 17/50 | Train Loss: 0.198 | Valid. MCAUC: 0.816\n",
      "2020-03-30 15:52:09,134 - INFO - Epoch: 18/50 | Train Loss: 0.191 | Valid. MCAUC: 0.817\n",
      "2020-03-30 15:52:15,140 - INFO - Epoch: 19/50 | Train Loss: 0.186 | Valid. MCAUC: 0.826\n",
      "2020-03-30 15:52:21,104 - INFO - Epoch: 20/50 | Train Loss: 0.182 | Valid. MCAUC: 0.823\n",
      "2020-03-30 15:52:27,142 - INFO - Epoch: 21/50 | Train Loss: 0.178 | Valid. MCAUC: 0.823\n",
      "2020-03-30 15:52:33,125 - INFO - Epoch: 22/50 | Train Loss: 0.172 | Valid. MCAUC: 0.825\n",
      "2020-03-30 15:52:39,089 - INFO - Epoch: 23/50 | Train Loss: 0.167 | Valid. MCAUC: 0.825\n",
      "2020-03-30 15:52:45,132 - INFO - Epoch: 24/50 | Train Loss: 0.165 | Valid. MCAUC: 0.826\n",
      "2020-03-30 15:52:51,140 - INFO - Epoch: 25/50 | Train Loss: 0.167 | Valid. MCAUC: 0.829\n",
      "2020-03-30 15:52:57,154 - INFO - Epoch: 26/50 | Train Loss: 0.158 | Valid. MCAUC: 0.829\n",
      "2020-03-30 15:53:03,124 - INFO - Epoch: 27/50 | Train Loss: 0.149 | Valid. MCAUC: 0.844\n",
      "2020-03-30 15:53:09,166 - INFO - Epoch: 28/50 | Train Loss: 0.145 | Valid. MCAUC: 0.842\n",
      "2020-03-30 15:53:15,154 - INFO - Epoch: 29/50 | Train Loss: 0.137 | Valid. MCAUC: 0.842\n",
      "2020-03-30 15:53:21,142 - INFO - Epoch: 30/50 | Train Loss: 0.133 | Valid. MCAUC: 0.847\n",
      "2020-03-30 15:53:27,220 - INFO - Epoch: 31/50 | Train Loss: 0.130 | Valid. MCAUC: 0.845\n",
      "2020-03-30 15:53:33,243 - INFO - Epoch: 32/50 | Train Loss: 0.126 | Valid. MCAUC: 0.850\n",
      "2020-03-30 15:53:39,316 - INFO - Epoch: 33/50 | Train Loss: 0.123 | Valid. MCAUC: 0.851\n",
      "2020-03-30 15:53:45,299 - INFO - Epoch: 34/50 | Train Loss: 0.120 | Valid. MCAUC: 0.847\n",
      "2020-03-30 15:53:51,345 - INFO - Epoch: 35/50 | Train Loss: 0.118 | Valid. MCAUC: 0.845\n",
      "2020-03-30 15:53:57,365 - INFO - Epoch: 36/50 | Train Loss: 0.115 | Valid. MCAUC: 0.852\n",
      "2020-03-30 15:54:03,346 - INFO - Epoch: 37/50 | Train Loss: 0.109 | Valid. MCAUC: 0.849\n",
      "2020-03-30 15:54:09,363 - INFO - Epoch: 38/50 | Train Loss: 0.106 | Valid. MCAUC: 0.850\n",
      "2020-03-30 15:54:15,391 - INFO - Epoch: 39/50 | Train Loss: 0.104 | Valid. MCAUC: 0.854\n",
      "2020-03-30 15:54:21,424 - INFO - Epoch: 40/50 | Train Loss: 0.101 | Valid. MCAUC: 0.856\n",
      "2020-03-30 15:54:27,417 - INFO - Epoch: 41/50 | Train Loss: 0.099 | Valid. MCAUC: 0.855\n",
      "2020-03-30 15:54:33,476 - INFO - Epoch: 42/50 | Train Loss: 0.096 | Valid. MCAUC: 0.854\n",
      "2020-03-30 15:54:39,494 - INFO - Epoch: 43/50 | Train Loss: 0.097 | Valid. MCAUC: 0.858\n",
      "2020-03-30 15:54:45,486 - INFO - Epoch: 44/50 | Train Loss: 0.093 | Valid. MCAUC: 0.863\n",
      "2020-03-30 15:54:51,513 - INFO - Epoch: 45/50 | Train Loss: 0.091 | Valid. MCAUC: 0.861\n",
      "2020-03-30 15:54:57,546 - INFO - Epoch: 46/50 | Train Loss: 0.088 | Valid. MCAUC: 0.859\n",
      "2020-03-30 15:55:03,590 - INFO - Epoch: 47/50 | Train Loss: 0.087 | Valid. MCAUC: 0.858\n",
      "2020-03-30 15:55:09,591 - INFO - Epoch: 48/50 | Train Loss: 0.086 | Valid. MCAUC: 0.860\n",
      "2020-03-30 15:55:15,665 - INFO - Epoch: 49/50 | Train Loss: 0.084 | Valid. MCAUC: 0.864\n",
      "2020-03-30 15:55:21,685 - INFO - Epoch: 50/50 | Train Loss: 0.081 | Valid. MCAUC: 0.863\n",
      "2020-03-30 15:55:21,695 - INFO - training model gru.\n",
      "\t -model_kwargs: {'dropout': 0.3, 'hidden_dim': 256, 'n_layers': 2}\n",
      "\t -loss_kwargs: {'pos_weight': None}\n",
      "\t -optim_kwargs: {'lr': 0.01}\n",
      "2020-03-30 15:55:27,753 - INFO - Epoch: 01/50 | Train Loss: 0.362 | Valid. MCAUC: 0.513\n",
      "2020-03-30 15:55:33,778 - INFO - Epoch: 02/50 | Train Loss: 0.330 | Valid. MCAUC: 0.522\n",
      "2020-03-30 15:55:39,864 - INFO - Epoch: 03/50 | Train Loss: 0.324 | Valid. MCAUC: 0.518\n",
      "2020-03-30 15:55:45,911 - INFO - Epoch: 04/50 | Train Loss: 0.328 | Valid. MCAUC: 0.547\n",
      "2020-03-30 15:55:51,912 - INFO - Epoch: 05/50 | Train Loss: 0.324 | Valid. MCAUC: 0.519\n",
      "2020-03-30 15:55:57,993 - INFO - Epoch: 06/50 | Train Loss: 0.325 | Valid. MCAUC: 0.505\n",
      "2020-03-30 15:56:04,014 - INFO - Epoch: 07/50 | Train Loss: 0.324 | Valid. MCAUC: 0.516\n",
      "2020-03-30 15:56:10,019 - INFO - Epoch: 08/50 | Train Loss: 0.325 | Valid. MCAUC: 0.494\n",
      "2020-03-30 15:56:16,043 - INFO - Epoch: 09/50 | Train Loss: 0.326 | Valid. MCAUC: 0.536\n",
      "2020-03-30 15:56:22,094 - INFO - Epoch: 10/50 | Train Loss: 0.326 | Valid. MCAUC: 0.562\n",
      "2020-03-30 15:56:28,134 - INFO - Epoch: 11/50 | Train Loss: 0.324 | Valid. MCAUC: 0.509\n",
      "2020-03-30 15:56:34,131 - INFO - Epoch: 12/50 | Train Loss: 0.327 | Valid. MCAUC: 0.490\n",
      "2020-03-30 15:56:40,207 - INFO - Epoch: 13/50 | Train Loss: 0.326 | Valid. MCAUC: 0.507\n",
      "2020-03-30 15:56:46,235 - INFO - Epoch: 14/50 | Train Loss: 0.326 | Valid. MCAUC: 0.510\n",
      "2020-03-30 15:56:52,243 - INFO - Epoch: 15/50 | Train Loss: 0.326 | Valid. MCAUC: 0.505\n",
      "2020-03-30 15:56:58,268 - INFO - Epoch: 16/50 | Train Loss: 0.319 | Valid. MCAUC: 0.521\n",
      "2020-03-30 15:57:04,309 - INFO - Epoch: 17/50 | Train Loss: 0.323 | Valid. MCAUC: 0.517\n",
      "2020-03-30 15:57:10,378 - INFO - Epoch: 18/50 | Train Loss: 0.325 | Valid. MCAUC: 0.530\n",
      "2020-03-30 15:57:16,382 - INFO - Epoch: 19/50 | Train Loss: 0.323 | Valid. MCAUC: 0.481\n",
      "2020-03-30 15:57:22,460 - INFO - Epoch: 20/50 | Train Loss: 0.325 | Valid. MCAUC: 0.521\n",
      "2020-03-30 15:57:28,487 - INFO - Epoch: 21/50 | Train Loss: 0.322 | Valid. MCAUC: 0.526\n",
      "2020-03-30 15:57:34,497 - INFO - Epoch: 22/50 | Train Loss: 0.321 | Valid. MCAUC: 0.528\n",
      "2020-03-30 15:57:40,524 - INFO - Epoch: 23/50 | Train Loss: 0.322 | Valid. MCAUC: 0.518\n",
      "2020-03-30 15:57:46,564 - INFO - Epoch: 24/50 | Train Loss: 0.322 | Valid. MCAUC: 0.515\n",
      "2020-03-30 15:57:52,646 - INFO - Epoch: 25/50 | Train Loss: 0.321 | Valid. MCAUC: 0.539\n",
      "2020-03-30 15:57:58,720 - INFO - Epoch: 26/50 | Train Loss: 0.320 | Valid. MCAUC: 0.489\n",
      "2020-03-30 15:58:04,796 - INFO - Epoch: 27/50 | Train Loss: 0.320 | Valid. MCAUC: 0.492\n",
      "2020-03-30 15:58:10,823 - INFO - Epoch: 28/50 | Train Loss: 0.319 | Valid. MCAUC: 0.490\n",
      "2020-03-30 15:58:16,826 - INFO - Epoch: 29/50 | Train Loss: 0.318 | Valid. MCAUC: 0.495\n",
      "2020-03-30 15:58:22,925 - INFO - Epoch: 30/50 | Train Loss: 0.320 | Valid. MCAUC: 0.525\n",
      "2020-03-30 15:58:28,967 - INFO - Epoch: 31/50 | Train Loss: 0.319 | Valid. MCAUC: 0.539\n",
      "2020-03-30 15:58:35,014 - INFO - Epoch: 32/50 | Train Loss: 0.307 | Valid. MCAUC: 0.538\n",
      "2020-03-30 15:58:41,010 - INFO - Epoch: 33/50 | Train Loss: 0.304 | Valid. MCAUC: 0.542\n",
      "2020-03-30 15:58:47,083 - INFO - Epoch: 34/50 | Train Loss: 0.304 | Valid. MCAUC: 0.549\n",
      "2020-03-30 15:58:53,176 - INFO - Epoch: 35/50 | Train Loss: 0.306 | Valid. MCAUC: 0.530\n",
      "2020-03-30 15:58:59,181 - INFO - Epoch: 36/50 | Train Loss: 0.304 | Valid. MCAUC: 0.556\n",
      "2020-03-30 15:59:05,205 - INFO - Epoch: 37/50 | Train Loss: 0.304 | Valid. MCAUC: 0.507\n",
      "2020-03-30 15:59:11,247 - INFO - Epoch: 38/50 | Train Loss: 0.305 | Valid. MCAUC: 0.532\n",
      "2020-03-30 15:59:17,289 - INFO - Epoch: 39/50 | Train Loss: 0.303 | Valid. MCAUC: 0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-30 15:59:23,287 - INFO - Epoch: 40/50 | Train Loss: 0.304 | Valid. MCAUC: 0.527\n",
      "2020-03-30 15:59:29,378 - INFO - Epoch: 41/50 | Train Loss: 0.304 | Valid. MCAUC: 0.510\n",
      "2020-03-30 15:59:35,399 - INFO - Epoch: 42/50 | Train Loss: 0.303 | Valid. MCAUC: 0.506\n",
      "2020-03-30 15:59:41,408 - INFO - Epoch: 43/50 | Train Loss: 0.302 | Valid. MCAUC: 0.526\n",
      "2020-03-30 15:59:47,434 - INFO - Epoch: 44/50 | Train Loss: 0.304 | Valid. MCAUC: 0.525\n",
      "2020-03-30 15:59:53,474 - INFO - Epoch: 45/50 | Train Loss: 0.304 | Valid. MCAUC: 0.517\n",
      "2020-03-30 15:59:59,520 - INFO - Epoch: 46/50 | Train Loss: 0.303 | Valid. MCAUC: 0.546\n",
      "2020-03-30 16:00:05,524 - INFO - Epoch: 47/50 | Train Loss: 0.303 | Valid. MCAUC: 0.503\n",
      "2020-03-30 16:00:11,591 - INFO - Epoch: 48/50 | Train Loss: 0.300 | Valid. MCAUC: 0.517\n",
      "2020-03-30 16:00:17,602 - INFO - Epoch: 49/50 | Train Loss: 0.303 | Valid. MCAUC: 0.505\n",
      "2020-03-30 16:00:23,590 - INFO - Epoch: 50/50 | Train Loss: 0.303 | Valid. MCAUC: 0.499\n",
      "2020-03-30 16:00:23,606 - INFO - training model gru.\n",
      "\t -model_kwargs: {'dropout': 0.3, 'hidden_dim': 256, 'n_layers': 3}\n",
      "\t -loss_kwargs: {'pos_weight': None}\n",
      "\t -optim_kwargs: {'lr': 0.001}\n",
      "2020-03-30 16:00:34,059 - INFO - Epoch: 01/50 | Train Loss: 0.337 | Valid. MCAUC: 0.576\n",
      "2020-03-30 16:00:44,545 - INFO - Epoch: 02/50 | Train Loss: 0.296 | Valid. MCAUC: 0.611\n",
      "2020-03-30 16:00:55,053 - INFO - Epoch: 03/50 | Train Loss: 0.290 | Valid. MCAUC: 0.663\n",
      "2020-03-30 16:01:05,533 - INFO - Epoch: 04/50 | Train Loss: 0.285 | Valid. MCAUC: 0.684\n",
      "2020-03-30 16:01:15,962 - INFO - Epoch: 05/50 | Train Loss: 0.280 | Valid. MCAUC: 0.719\n",
      "2020-03-30 16:01:26,393 - INFO - Epoch: 06/50 | Train Loss: 0.274 | Valid. MCAUC: 0.737\n",
      "2020-03-30 16:01:36,864 - INFO - Epoch: 07/50 | Train Loss: 0.266 | Valid. MCAUC: 0.748\n",
      "2020-03-30 16:01:47,362 - INFO - Epoch: 08/50 | Train Loss: 0.259 | Valid. MCAUC: 0.765\n",
      "2020-03-30 16:01:57,834 - INFO - Epoch: 09/50 | Train Loss: 0.253 | Valid. MCAUC: 0.774\n",
      "2020-03-30 16:02:08,300 - INFO - Epoch: 10/50 | Train Loss: 0.245 | Valid. MCAUC: 0.787\n",
      "2020-03-30 16:02:18,815 - INFO - Epoch: 11/50 | Train Loss: 0.238 | Valid. MCAUC: 0.788\n",
      "2020-03-30 16:02:29,292 - INFO - Epoch: 12/50 | Train Loss: 0.234 | Valid. MCAUC: 0.786\n",
      "2020-03-30 16:02:39,740 - INFO - Epoch: 13/50 | Train Loss: 0.234 | Valid. MCAUC: 0.802\n",
      "2020-03-30 16:02:50,207 - INFO - Epoch: 14/50 | Train Loss: 0.225 | Valid. MCAUC: 0.801\n",
      "2020-03-30 16:03:00,731 - INFO - Epoch: 15/50 | Train Loss: 0.222 | Valid. MCAUC: 0.806\n",
      "2020-03-30 16:03:11,244 - INFO - Epoch: 16/50 | Train Loss: 0.209 | Valid. MCAUC: 0.817\n",
      "2020-03-30 16:03:21,721 - INFO - Epoch: 17/50 | Train Loss: 0.199 | Valid. MCAUC: 0.816\n",
      "2020-03-30 16:03:32,195 - INFO - Epoch: 18/50 | Train Loss: 0.193 | Valid. MCAUC: 0.819\n",
      "2020-03-30 16:03:42,702 - INFO - Epoch: 19/50 | Train Loss: 0.188 | Valid. MCAUC: 0.823\n",
      "2020-03-30 16:03:53,205 - INFO - Epoch: 20/50 | Train Loss: 0.184 | Valid. MCAUC: 0.825\n",
      "2020-03-30 16:04:03,709 - INFO - Epoch: 21/50 | Train Loss: 0.177 | Valid. MCAUC: 0.826\n",
      "2020-03-30 16:04:14,165 - INFO - Epoch: 22/50 | Train Loss: 0.171 | Valid. MCAUC: 0.830\n",
      "2020-03-30 16:04:24,649 - INFO - Epoch: 23/50 | Train Loss: 0.165 | Valid. MCAUC: 0.831\n",
      "2020-03-30 16:04:35,135 - INFO - Epoch: 24/50 | Train Loss: 0.158 | Valid. MCAUC: 0.830\n",
      "2020-03-30 16:04:45,573 - INFO - Epoch: 25/50 | Train Loss: 0.153 | Valid. MCAUC: 0.832\n",
      "2020-03-30 16:04:56,019 - INFO - Epoch: 26/50 | Train Loss: 0.148 | Valid. MCAUC: 0.838\n",
      "2020-03-30 16:05:06,483 - INFO - Epoch: 27/50 | Train Loss: 0.144 | Valid. MCAUC: 0.837\n",
      "2020-03-30 16:05:16,939 - INFO - Epoch: 28/50 | Train Loss: 0.144 | Valid. MCAUC: 0.840\n",
      "2020-03-30 16:05:27,373 - INFO - Epoch: 29/50 | Train Loss: 0.142 | Valid. MCAUC: 0.842\n",
      "2020-03-30 16:05:37,840 - INFO - Epoch: 30/50 | Train Loss: 0.135 | Valid. MCAUC: 0.840\n",
      "2020-03-30 16:05:48,265 - INFO - Epoch: 31/50 | Train Loss: 0.126 | Valid. MCAUC: 0.841\n",
      "2020-03-30 16:05:58,745 - INFO - Epoch: 32/50 | Train Loss: 0.121 | Valid. MCAUC: 0.847\n",
      "2020-03-30 16:06:09,199 - INFO - Epoch: 33/50 | Train Loss: 0.114 | Valid. MCAUC: 0.847\n",
      "2020-03-30 16:06:19,645 - INFO - Epoch: 34/50 | Train Loss: 0.109 | Valid. MCAUC: 0.847\n",
      "2020-03-30 16:06:30,118 - INFO - Epoch: 35/50 | Train Loss: 0.103 | Valid. MCAUC: 0.848\n",
      "2020-03-30 16:06:40,614 - INFO - Epoch: 36/50 | Train Loss: 0.100 | Valid. MCAUC: 0.847\n",
      "2020-03-30 16:06:51,039 - INFO - Epoch: 37/50 | Train Loss: 0.096 | Valid. MCAUC: 0.847\n",
      "2020-03-30 16:07:01,518 - INFO - Epoch: 38/50 | Train Loss: 0.093 | Valid. MCAUC: 0.850\n",
      "2020-03-30 16:07:11,973 - INFO - Epoch: 39/50 | Train Loss: 0.090 | Valid. MCAUC: 0.848\n",
      "2020-03-30 16:07:22,415 - INFO - Epoch: 40/50 | Train Loss: 0.087 | Valid. MCAUC: 0.846\n",
      "2020-03-30 16:07:32,826 - INFO - Epoch: 41/50 | Train Loss: 0.085 | Valid. MCAUC: 0.846\n",
      "2020-03-30 16:07:43,270 - INFO - Epoch: 42/50 | Train Loss: 0.082 | Valid. MCAUC: 0.843\n",
      "2020-03-30 16:07:53,719 - INFO - Epoch: 43/50 | Train Loss: 0.080 | Valid. MCAUC: 0.847\n",
      "2020-03-30 16:08:04,164 - INFO - Epoch: 44/50 | Train Loss: 0.078 | Valid. MCAUC: 0.841\n",
      "2020-03-30 16:08:14,605 - INFO - Epoch: 45/50 | Train Loss: 0.076 | Valid. MCAUC: 0.844\n",
      "2020-03-30 16:08:25,036 - INFO - Epoch: 46/50 | Train Loss: 0.073 | Valid. MCAUC: 0.846\n",
      "2020-03-30 16:08:35,519 - INFO - Epoch: 47/50 | Train Loss: 0.073 | Valid. MCAUC: 0.850\n",
      "2020-03-30 16:08:45,963 - INFO - Epoch: 48/50 | Train Loss: 0.070 | Valid. MCAUC: 0.848\n",
      "2020-03-30 16:08:56,385 - INFO - Epoch: 49/50 | Train Loss: 0.069 | Valid. MCAUC: 0.850\n",
      "2020-03-30 16:09:06,898 - INFO - Epoch: 50/50 | Train Loss: 0.065 | Valid. MCAUC: 0.851\n",
      "2020-03-30 16:09:06,915 - INFO - training model gru.\n",
      "\t -model_kwargs: {'dropout': 0.3, 'hidden_dim': 256, 'n_layers': 3}\n",
      "\t -loss_kwargs: {'pos_weight': None}\n",
      "\t -optim_kwargs: {'lr': 0.01}\n",
      "2020-03-30 16:09:17,452 - INFO - Epoch: 01/50 | Train Loss: 0.364 | Valid. MCAUC: 0.578\n",
      "2020-03-30 16:09:27,897 - INFO - Epoch: 02/50 | Train Loss: 0.332 | Valid. MCAUC: 0.613\n",
      "2020-03-30 16:09:38,359 - INFO - Epoch: 03/50 | Train Loss: 0.324 | Valid. MCAUC: 0.534\n",
      "2020-03-30 16:09:48,833 - INFO - Epoch: 04/50 | Train Loss: 0.329 | Valid. MCAUC: 0.491\n",
      "2020-03-30 16:09:59,310 - INFO - Epoch: 05/50 | Train Loss: 0.327 | Valid. MCAUC: 0.493\n",
      "2020-03-30 16:10:09,778 - INFO - Epoch: 06/50 | Train Loss: 0.329 | Valid. MCAUC: 0.552\n",
      "2020-03-30 16:10:20,283 - INFO - Epoch: 07/50 | Train Loss: 0.328 | Valid. MCAUC: 0.533\n",
      "2020-03-30 16:10:30,781 - INFO - Epoch: 08/50 | Train Loss: 0.328 | Valid. MCAUC: 0.542\n",
      "2020-03-30 16:10:41,326 - INFO - Epoch: 09/50 | Train Loss: 0.330 | Valid. MCAUC: 0.487\n",
      "2020-03-30 16:10:51,795 - INFO - Epoch: 10/50 | Train Loss: 0.330 | Valid. MCAUC: 0.476\n",
      "2020-03-30 16:11:02,267 - INFO - Epoch: 11/50 | Train Loss: 0.329 | Valid. MCAUC: 0.559\n",
      "2020-03-30 16:11:12,753 - INFO - Epoch: 12/50 | Train Loss: 0.330 | Valid. MCAUC: 0.471\n",
      "2020-03-30 16:11:23,234 - INFO - Epoch: 13/50 | Train Loss: 0.328 | Valid. MCAUC: 0.448\n",
      "2020-03-30 16:11:33,731 - INFO - Epoch: 14/50 | Train Loss: 0.328 | Valid. MCAUC: 0.459\n",
      "2020-03-30 16:11:44,201 - INFO - Epoch: 15/50 | Train Loss: 0.331 | Valid. MCAUC: 0.463\n",
      "2020-03-30 16:11:54,664 - INFO - Epoch: 16/50 | Train Loss: 0.321 | Valid. MCAUC: 0.460\n",
      "2020-03-30 16:12:05,127 - INFO - Epoch: 17/50 | Train Loss: 0.326 | Valid. MCAUC: 0.463\n",
      "2020-03-30 16:12:15,601 - INFO - Epoch: 18/50 | Train Loss: 0.327 | Valid. MCAUC: 0.539\n",
      "2020-03-30 16:12:26,071 - INFO - Epoch: 19/50 | Train Loss: 0.326 | Valid. MCAUC: 0.528\n",
      "2020-03-30 16:12:36,562 - INFO - Epoch: 20/50 | Train Loss: 0.325 | Valid. MCAUC: 0.549\n",
      "2020-03-30 16:12:47,047 - INFO - Epoch: 21/50 | Train Loss: 0.322 | Valid. MCAUC: 0.535\n",
      "2020-03-30 16:12:57,519 - INFO - Epoch: 22/50 | Train Loss: 0.323 | Valid. MCAUC: 0.557\n",
      "2020-03-30 16:13:08,005 - INFO - Epoch: 23/50 | Train Loss: 0.322 | Valid. MCAUC: 0.528\n",
      "2020-03-30 16:13:18,490 - INFO - Epoch: 24/50 | Train Loss: 0.321 | Valid. MCAUC: 0.531\n",
      "2020-03-30 16:13:28,993 - INFO - Epoch: 25/50 | Train Loss: 0.321 | Valid. MCAUC: 0.536\n",
      "2020-03-30 16:13:39,479 - INFO - Epoch: 26/50 | Train Loss: 0.320 | Valid. MCAUC: 0.545\n",
      "2020-03-30 16:13:49,966 - INFO - Epoch: 27/50 | Train Loss: 0.322 | Valid. MCAUC: 0.530\n",
      "2020-03-30 16:14:00,461 - INFO - Epoch: 28/50 | Train Loss: 0.321 | Valid. MCAUC: 0.530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-30 16:14:10,956 - INFO - Epoch: 29/50 | Train Loss: 0.321 | Valid. MCAUC: 0.518\n",
      "2020-03-30 16:14:21,425 - INFO - Epoch: 30/50 | Train Loss: 0.322 | Valid. MCAUC: 0.520\n",
      "2020-03-30 16:14:31,897 - INFO - Epoch: 31/50 | Train Loss: 0.322 | Valid. MCAUC: 0.502\n",
      "2020-03-30 16:14:42,397 - INFO - Epoch: 32/50 | Train Loss: 0.310 | Valid. MCAUC: 0.525\n",
      "2020-03-30 16:14:52,870 - INFO - Epoch: 33/50 | Train Loss: 0.305 | Valid. MCAUC: 0.512\n",
      "2020-03-30 16:15:03,352 - INFO - Epoch: 34/50 | Train Loss: 0.306 | Valid. MCAUC: 0.516\n",
      "2020-03-30 16:15:13,834 - INFO - Epoch: 35/50 | Train Loss: 0.306 | Valid. MCAUC: 0.517\n",
      "2020-03-30 16:15:24,319 - INFO - Epoch: 36/50 | Train Loss: 0.305 | Valid. MCAUC: 0.525\n",
      "2020-03-30 16:15:34,815 - INFO - Epoch: 37/50 | Train Loss: 0.305 | Valid. MCAUC: 0.535\n",
      "2020-03-30 16:15:45,282 - INFO - Epoch: 38/50 | Train Loss: 0.304 | Valid. MCAUC: 0.535\n",
      "2020-03-30 16:15:55,754 - INFO - Epoch: 39/50 | Train Loss: 0.305 | Valid. MCAUC: 0.538\n",
      "2020-03-30 16:16:06,238 - INFO - Epoch: 40/50 | Train Loss: 0.305 | Valid. MCAUC: 0.523\n",
      "2020-03-30 16:16:16,740 - INFO - Epoch: 41/50 | Train Loss: 0.303 | Valid. MCAUC: 0.502\n",
      "2020-03-30 16:16:27,215 - INFO - Epoch: 42/50 | Train Loss: 0.304 | Valid. MCAUC: 0.496\n",
      "2020-03-30 16:16:37,683 - INFO - Epoch: 43/50 | Train Loss: 0.304 | Valid. MCAUC: 0.507\n",
      "2020-03-30 16:16:48,172 - INFO - Epoch: 44/50 | Train Loss: 0.306 | Valid. MCAUC: 0.525\n",
      "2020-03-30 16:16:58,643 - INFO - Epoch: 45/50 | Train Loss: 0.303 | Valid. MCAUC: 0.473\n",
      "2020-03-30 16:17:09,114 - INFO - Epoch: 46/50 | Train Loss: 0.304 | Valid. MCAUC: 0.492\n",
      "2020-03-30 16:17:19,565 - INFO - Epoch: 47/50 | Train Loss: 0.305 | Valid. MCAUC: 0.512\n",
      "2020-03-30 16:17:30,020 - INFO - Epoch: 48/50 | Train Loss: 0.301 | Valid. MCAUC: 0.530\n",
      "2020-03-30 16:17:40,509 - INFO - Epoch: 49/50 | Train Loss: 0.301 | Valid. MCAUC: 0.538\n",
      "2020-03-30 16:17:50,986 - INFO - Epoch: 50/50 | Train Loss: 0.301 | Valid. MCAUC: 0.546\n",
      "2020-03-30 16:17:50,990 - INFO - training model gru.\n",
      "\t -model_kwargs: {'dropout': 0.3, 'hidden_dim': 128, 'n_layers': 2}\n",
      "\t -loss_kwargs: {'pos_weight': None}\n",
      "\t -optim_kwargs: {'lr': 0.001}\n",
      "2020-03-30 16:17:54,940 - INFO - Epoch: 01/50 | Train Loss: 0.371 | Valid. MCAUC: 0.559\n",
      "2020-03-30 16:17:58,862 - INFO - Epoch: 02/50 | Train Loss: 0.298 | Valid. MCAUC: 0.581\n",
      "2020-03-30 16:18:02,766 - INFO - Epoch: 03/50 | Train Loss: 0.294 | Valid. MCAUC: 0.622\n",
      "2020-03-30 16:18:06,687 - INFO - Epoch: 04/50 | Train Loss: 0.292 | Valid. MCAUC: 0.646\n",
      "2020-03-30 16:18:10,577 - INFO - Epoch: 05/50 | Train Loss: 0.287 | Valid. MCAUC: 0.670\n",
      "2020-03-30 16:18:14,551 - INFO - Epoch: 06/50 | Train Loss: 0.283 | Valid. MCAUC: 0.691\n",
      "2020-03-30 16:18:18,448 - INFO - Epoch: 07/50 | Train Loss: 0.279 | Valid. MCAUC: 0.703\n",
      "2020-03-30 16:18:22,354 - INFO - Epoch: 08/50 | Train Loss: 0.274 | Valid. MCAUC: 0.720\n",
      "2020-03-30 16:18:26,293 - INFO - Epoch: 09/50 | Train Loss: 0.270 | Valid. MCAUC: 0.736\n",
      "2020-03-30 16:18:30,156 - INFO - Epoch: 10/50 | Train Loss: 0.263 | Valid. MCAUC: 0.758\n",
      "2020-03-30 16:18:34,111 - INFO - Epoch: 11/50 | Train Loss: 0.258 | Valid. MCAUC: 0.763\n",
      "2020-03-30 16:18:37,993 - INFO - Epoch: 12/50 | Train Loss: 0.252 | Valid. MCAUC: 0.774\n",
      "2020-03-30 16:18:41,859 - INFO - Epoch: 13/50 | Train Loss: 0.247 | Valid. MCAUC: 0.776\n",
      "2020-03-30 16:18:45,812 - INFO - Epoch: 14/50 | Train Loss: 0.242 | Valid. MCAUC: 0.783\n",
      "2020-03-30 16:18:49,681 - INFO - Epoch: 15/50 | Train Loss: 0.236 | Valid. MCAUC: 0.782\n",
      "2020-03-30 16:18:53,629 - INFO - Epoch: 16/50 | Train Loss: 0.234 | Valid. MCAUC: 0.786\n",
      "2020-03-30 16:18:57,491 - INFO - Epoch: 17/50 | Train Loss: 0.228 | Valid. MCAUC: 0.782\n",
      "2020-03-30 16:19:01,364 - INFO - Epoch: 18/50 | Train Loss: 0.224 | Valid. MCAUC: 0.785\n",
      "2020-03-30 16:19:05,243 - INFO - Epoch: 19/50 | Train Loss: 0.221 | Valid. MCAUC: 0.787\n",
      "2020-03-30 16:19:09,111 - INFO - Epoch: 20/50 | Train Loss: 0.220 | Valid. MCAUC: 0.785\n",
      "2020-03-30 16:19:12,992 - INFO - Epoch: 21/50 | Train Loss: 0.216 | Valid. MCAUC: 0.790\n",
      "2020-03-30 16:19:16,856 - INFO - Epoch: 22/50 | Train Loss: 0.214 | Valid. MCAUC: 0.789\n",
      "2020-03-30 16:19:20,730 - INFO - Epoch: 23/50 | Train Loss: 0.210 | Valid. MCAUC: 0.788\n",
      "2020-03-30 16:19:24,609 - INFO - Epoch: 24/50 | Train Loss: 0.208 | Valid. MCAUC: 0.791\n",
      "2020-03-30 16:19:28,486 - INFO - Epoch: 25/50 | Train Loss: 0.204 | Valid. MCAUC: 0.798\n",
      "2020-03-30 16:19:32,349 - INFO - Epoch: 26/50 | Train Loss: 0.203 | Valid. MCAUC: 0.792\n",
      "2020-03-30 16:19:36,294 - INFO - Epoch: 27/50 | Train Loss: 0.203 | Valid. MCAUC: 0.797\n",
      "2020-03-30 16:19:40,176 - INFO - Epoch: 28/50 | Train Loss: 0.199 | Valid. MCAUC: 0.797\n",
      "2020-03-30 16:19:44,043 - INFO - Epoch: 29/50 | Train Loss: 0.196 | Valid. MCAUC: 0.798\n",
      "2020-03-30 16:19:47,911 - INFO - Epoch: 30/50 | Train Loss: 0.196 | Valid. MCAUC: 0.812\n",
      "2020-03-30 16:19:51,774 - INFO - Epoch: 31/50 | Train Loss: 0.193 | Valid. MCAUC: 0.807\n",
      "2020-03-30 16:19:55,680 - INFO - Epoch: 32/50 | Train Loss: 0.187 | Valid. MCAUC: 0.811\n",
      "2020-03-30 16:19:59,567 - INFO - Epoch: 33/50 | Train Loss: 0.185 | Valid. MCAUC: 0.808\n",
      "2020-03-30 16:20:03,456 - INFO - Epoch: 34/50 | Train Loss: 0.182 | Valid. MCAUC: 0.808\n",
      "2020-03-30 16:20:07,349 - INFO - Epoch: 35/50 | Train Loss: 0.180 | Valid. MCAUC: 0.811\n",
      "2020-03-30 16:20:11,229 - INFO - Epoch: 36/50 | Train Loss: 0.179 | Valid. MCAUC: 0.811\n",
      "2020-03-30 16:20:15,103 - INFO - Epoch: 37/50 | Train Loss: 0.178 | Valid. MCAUC: 0.806\n",
      "2020-03-30 16:20:18,974 - INFO - Epoch: 38/50 | Train Loss: 0.176 | Valid. MCAUC: 0.809\n",
      "2020-03-30 16:20:22,861 - INFO - Epoch: 39/50 | Train Loss: 0.174 | Valid. MCAUC: 0.812\n",
      "2020-03-30 16:20:26,738 - INFO - Epoch: 40/50 | Train Loss: 0.173 | Valid. MCAUC: 0.810\n",
      "2020-03-30 16:20:30,604 - INFO - Epoch: 41/50 | Train Loss: 0.172 | Valid. MCAUC: 0.812\n",
      "2020-03-30 16:20:34,485 - INFO - Epoch: 42/50 | Train Loss: 0.170 | Valid. MCAUC: 0.816\n",
      "2020-03-30 16:20:38,358 - INFO - Epoch: 43/50 | Train Loss: 0.167 | Valid. MCAUC: 0.814\n",
      "2020-03-30 16:20:42,231 - INFO - Epoch: 44/50 | Train Loss: 0.166 | Valid. MCAUC: 0.811\n",
      "2020-03-30 16:20:46,105 - INFO - Epoch: 45/50 | Train Loss: 0.165 | Valid. MCAUC: 0.814\n",
      "2020-03-30 16:20:49,978 - INFO - Epoch: 46/50 | Train Loss: 0.163 | Valid. MCAUC: 0.820\n",
      "2020-03-30 16:20:53,890 - INFO - Epoch: 47/50 | Train Loss: 0.162 | Valid. MCAUC: 0.818\n",
      "2020-03-30 16:20:57,765 - INFO - Epoch: 48/50 | Train Loss: 0.160 | Valid. MCAUC: 0.815\n",
      "2020-03-30 16:21:01,641 - INFO - Epoch: 49/50 | Train Loss: 0.160 | Valid. MCAUC: 0.817\n",
      "2020-03-30 16:21:05,519 - INFO - Epoch: 50/50 | Train Loss: 0.160 | Valid. MCAUC: 0.818\n",
      "2020-03-30 16:21:05,523 - INFO - training model gru.\n",
      "\t -model_kwargs: {'dropout': 0.3, 'hidden_dim': 128, 'n_layers': 2}\n",
      "\t -loss_kwargs: {'pos_weight': None}\n",
      "\t -optim_kwargs: {'lr': 0.01}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-cb50de2a1e17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                                          \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparamgrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                          \u001b[0mtrainloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                                          validloader=validloader) \n\u001b[0m",
      "\u001b[0;32m<ipython-input-136-e658b8f639ce>\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(model_name, param_grid, trainloader, validloader, n_epochs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmc_auc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_criterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmc_auc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mepoch_best_valid_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-113-f54243b8a54d>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, criterion)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-45bd806eb0b5>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, Yscores, Yclasses)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0maucall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_tag_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#             plt.plot(fpr, tpr, lw=0.5, alpha=0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \"\"\"\n\u001b[1;32m    770\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 771\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "paramgrid = {\n",
    "    'model.hidden_dim': [256, 128, 64],\n",
    "    'model.dropout': [0.3, 0.2],\n",
    "    'model.n_layers': [2, 3] ,\n",
    "    'loss.pos_weight': [None, pos_cnt/num_train],\n",
    "    'optim.lr': [1e-3, 1e-2]\n",
    "}\n",
    "\n",
    "# paramgrid = {\n",
    "#     'model.hidden_dim': [128, 64],\n",
    "#     'model.dropout': [0.2],\n",
    "#     'model.n_layers': [2] ,\n",
    "#     'loss.pos_weight': [torch.from_numpy(pos_cnt/num_train)],\n",
    "#     'optim.lr': [1e-3, 1e-2]\n",
    "# }\n",
    "\n",
    "trainloader = DataLoader(mfcc_train,\n",
    "                         batch_size=64,\n",
    "                         collate_fn=MyPadCollate(batch_first=True))\n",
    "\n",
    "validloader = DataLoader(mfcc_valid,\n",
    "                       batch_size=64,\n",
    "                       collate_fn=MyPadCollate(batch_first=True))\n",
    "\n",
    "best_save_path, best_score = grid_search('gru',\n",
    "                                         param_grid=paramgrid,\n",
    "                                         trainloader=trainloader,\n",
    "                                         validloader=validloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ckpt/gru_mcauc_0.698.pt\n",
      "0.6862989427978575 0.6864538939506115\n",
      "0.6976500234683715 0.699349398878703\n"
     ]
    }
   ],
   "source": [
    "# confirm score on training set and validation set\n",
    "print(best_save_path)\n",
    "model = load_model(best_save_path)\n",
    "\n",
    "allloader = DataLoader(mfcc_dataset,\n",
    "                       batch_size=128,\n",
    "                       collate_fn=MyPadCollate(True)\n",
    "                      )\n",
    "\n",
    "pred, (mc_auc, auc) = evaluate(model, allloader, AUROC(len(tagnames)))\n",
    "print(mc_auc, auc)\n",
    "\n",
    "pred, (mc_auc, auc) = evaluate(model, validloader,\n",
    "                               AUROC(len(tagnames)))\n",
    "print(mc_auc, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(tagnames)\n",
    "pseudo_test_label = np.random.randint(2, size=(len(test_mfccs), n))\n",
    "\n",
    "test_dataset = MFCCDataset(test_mfccs, pseudo_test_label)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=128,\n",
    "                         collate_fn=MyPadCollate())\n",
    "\n",
    "test_preds, _ = evaluate(model, test_loader,\n",
    "                         AUROC(len(tagnames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = os.path.basename(best_save_path)[:-2]+'csv'\n",
    "write_csv_kaggle_tags(save_name, tagnames, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
